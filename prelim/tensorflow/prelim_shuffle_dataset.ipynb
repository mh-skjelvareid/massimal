{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f570a0f9-eaf5-4338-b63f-31c05f2b0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable TensorFlow debugging info and warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 2: Info and warnings not displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d30d62-8de5-4239-b6a3-d2b1c15fc92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "#import pathlib\n",
    "#import tqdm\n",
    "#import annotation, misc, hyspec_io, image_render\n",
    "#import skimage.exposure\n",
    "import tensorflow as tf\n",
    "#import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ff6b64-ac11-4921-a91d-865015652edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPUs (in case of Tensorflow trying to use GPUs and raising errors)\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d357160c-b2e0-484f-a0d0-5fb91cb73766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (Note: Use double backslash on Windows)\n",
    "tiles_dataset_path = 'D:\\\\Larvik_Olberg\\\\Hyperspectral\\\\20210825\\\\OlbergAreaS\\\\5c_Rad_Georef_SGC_PCA_Tiles\\\\20210825_Olberg_PCA_TrainValDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73a6c01e-7b30-4701-a8e5-2adb05321d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (or, rather, pointer to dataset)\n",
    "dataset = tf.data.experimental.load(tiles_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5256766f-7840-4d45-88a9-6df3166eac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset specification: <_LoadDataset element_spec=(TensorSpec(shape=(128, 128, 8), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128), dtype=tf.int32, name=None))>\n",
      "Number of tiles: 459\n"
     ]
    }
   ],
   "source": [
    "# Show dataset details\n",
    "n_tiles = int(dataset.cardinality())\n",
    "print(f'Dataset specification: {dataset}')\n",
    "print(f'Number of tiles: {n_tiles}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38ed30c3-0a7c-4fbf-aabb-e8943f652387",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = dataset.shuffle(buffer_size=n_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ddd1db-d0e1-4b97-a67f-85239a6c0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = shuffled_dataset.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea27a2c-042b-4fed-856c-a951e425f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 128)\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 128)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for image_tile, label_tile in small_dataset.as_numpy_iterator():\n",
    "    print(label_tile.shape)\n",
    "    print(type(label_tile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d55a603-981e-4a13-bf03-8ee526f98b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_generator(dataset,k):\n",
    "    \"\"\" Generator for K-fold splitting into training and validation datasets\n",
    "    \n",
    "    # Arguments:\n",
    "    dataset    Tensorflow dataset\n",
    "    k          Number of folds (see https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "    \n",
    "    # Returns\n",
    "    training_dataset      Tensorflow dataset\n",
    "    validation_dataset    Tensorflow dataset\n",
    "    \n",
    "    # Notes:\n",
    "    The generator returns k sets of training and validation datasets when iterated over.\n",
    "    \n",
    "    # Example use:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((np.arange(9),np.arange(9)%3))\n",
    "    for data,label in dataset.as_numpy_iterator():\n",
    "        print(f'Data: {data}, label: {label}')\n",
    "    for training_dataset, validation_dataset in kfold_generator(dataset,3):\n",
    "        print('----')\n",
    "        for data,label in training_dataset.as_numpy_iterator():\n",
    "            print(f'Training data: {data}, label: {label}')\n",
    "        for data,label in validation_dataset.as_numpy_iterator():\n",
    "            print(f'Validation data: {data}, label: {label}')\n",
    "    \"\"\"\n",
    "    n_datapoints = dataset.cardinality()\n",
    "    dataset = dataset.shuffle(n_datapoints,reshuffle_each_iteration=False)\n",
    "    samples_per_fold = n_datapoints//k\n",
    "    for i in range(k):\n",
    "        validation_dataset = dataset.skip(i*samples_per_fold).take(samples_per_fold)\n",
    "        # Merge parts before/after validation dataset to create training dataset\n",
    "        training_dataset = dataset.take(i*samples_per_fold)\n",
    "        training_dataset = training_dataset.concatenate(dataset.skip((i+1)*samples_per_fold).take((k-i-1)*samples_per_fold))\n",
    "        yield (training_dataset,validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "607ad911-a9ba-4d76-8fad-2d8a722675ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 306\n",
      "Size of validation dataset: 153\n",
      "Size of training dataset: 306\n",
      "Size of validation dataset: 153\n",
      "Size of training dataset: 306\n",
      "Size of validation dataset: 153\n"
     ]
    }
   ],
   "source": [
    "for training_dataset, validation_dataset in kfold_generator(dataset,3):\n",
    "    print(f'Size of training dataset: {training_dataset.cardinality()}')\n",
    "    print(f'Size of validation dataset: {validation_dataset.cardinality()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "565ecaec-e1c7-44c7-934c-95dd996d8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.take(0)\n",
    "b = dataset.skip(3).take(3)\n",
    "c = a.concatenate(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be018e94-937a-488a-bda8-07be75756d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(a.cardinality())\n",
    "print(b.cardinality())\n",
    "print(c.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10ff39b2-63fc-444c-a399-eba5e04b442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((np.arange(9),np.arange(9)%3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e46f74a-5469-4793-9cb3-a3b50f68a36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 0, label: 0\n",
      "Data: 1, label: 1\n",
      "Data: 2, label: 2\n",
      "Data: 3, label: 0\n",
      "Data: 4, label: 1\n",
      "Data: 5, label: 2\n",
      "Data: 6, label: 0\n",
      "Data: 7, label: 1\n",
      "Data: 8, label: 2\n"
     ]
    }
   ],
   "source": [
    "for data,label in dataset.as_numpy_iterator():\n",
    "    print(f'Data: {data}, label: {label}')\n",
    "    #print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d299471-b974-4795-96fd-5d4776c4b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Training data: 7, label: 1\n",
      "Training data: 0, label: 0\n",
      "Training data: 3, label: 0\n",
      "Training data: 4, label: 1\n",
      "Training data: 1, label: 1\n",
      "Training data: 2, label: 2\n",
      "Validation data: 6, label: 0\n",
      "Validation data: 5, label: 2\n",
      "Validation data: 8, label: 2\n",
      "----\n",
      "Training data: 6, label: 0\n",
      "Training data: 5, label: 2\n",
      "Training data: 8, label: 2\n",
      "Training data: 4, label: 1\n",
      "Training data: 1, label: 1\n",
      "Training data: 2, label: 2\n",
      "Validation data: 7, label: 1\n",
      "Validation data: 0, label: 0\n",
      "Validation data: 3, label: 0\n",
      "----\n",
      "Training data: 6, label: 0\n",
      "Training data: 5, label: 2\n",
      "Training data: 8, label: 2\n",
      "Training data: 7, label: 1\n",
      "Training data: 0, label: 0\n",
      "Training data: 3, label: 0\n",
      "Validation data: 4, label: 1\n",
      "Validation data: 1, label: 1\n",
      "Validation data: 2, label: 2\n"
     ]
    }
   ],
   "source": [
    "for training_dataset, validation_dataset in kfold_generator(dataset,3):\n",
    "    print('----')\n",
    "    for data,label in training_dataset.as_numpy_iterator():\n",
    "        print(f'Training data: {data}, label: {label}')\n",
    "    for data,label in validation_dataset.as_numpy_iterator():\n",
    "        print(f'Validation data: {data}, label: {label}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
