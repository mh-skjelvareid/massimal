{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f570a0f9-eaf5-4338-b63f-31c05f2b0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable TensorFlow debugging info and warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 2: Info and warnings not displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d30d62-8de5-4239-b6a3-d2b1c15fc92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.ensemble\n",
    "import pathlib\n",
    "\n",
    "# Local imports\n",
    "import annotation, hyspec_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ff6b64-ac11-4921-a91d-865015652edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPUs (in case of Tensorflow trying to use GPUs and raising errors)\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a824a29-dbeb-4a99-bb8e-07d84bd06dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "VAL_FRAC = 0.3\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d357160c-b2e0-484f-a0d0-5fb91cb73766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths \n",
    "base_dir = pathlib.Path('/media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS')\n",
    "tiles_dataset_path = base_dir / '5c_Rad_Georef_SGC_PCA_Tiles/20210825_Olberg_PCA_TrainValDataset'\n",
    "train_dataset_path = base_dir / '5c_Rad_Georef_SGC_PCA_Tiles/20210825_Olberg_PCA_TrainDataset'\n",
    "val_dataset_path = base_dir / '5c_Rad_Georef_SGC_PCA_Tiles/20210825_Olberg_PCA_ValDataset'\n",
    "class_dict_path =  base_dir / '4c_Rad_Georef_SGC_Tiles/tile_classes_merged_NGT.json'\n",
    "unet_model_save_dir = base_dir /  'X_SavedKerasModels'\n",
    "tensorboard_log_dir = base_dir / 'X_TensorboardLogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af62da8-7a32-4f80-92bb-b0f53eec6cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background: 0\n",
      "Sand: 1\n",
      "Zostera marina: 2\n",
      "Zostera marina with turf algae: 3\n",
      "Rockweed: 4\n",
      "Other algae: 5\n"
     ]
    }
   ],
   "source": [
    "# Load class label dictionary\n",
    "class_dict = {'Background':0}\n",
    "class_dict.update(annotation.read_class_dict(class_dict_path))\n",
    "for key,value in class_dict.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de087c24-f686-45f0-99e3-89f2e061d580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/5c_Rad_Georef_SGC_PCA_Tiles/20210825_Olberg_PCA_TrainValDataset')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a6c01e-7b30-4701-a8e5-2adb05321d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (or, rather, pointer to dataset)\n",
    "dataset = tf.data.experimental.load(str(tiles_dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5256766f-7840-4d45-88a9-6df3166eac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset specification: <_LoadDataset element_spec=(TensorSpec(shape=(128, 128, 8), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128), dtype=tf.int32, name=None))>\n",
      "Number of tiles: 459\n"
     ]
    }
   ],
   "source": [
    "# Show dataset details\n",
    "n_tiles = int(dataset.cardinality())\n",
    "print(f'Dataset specification: {dataset}')\n",
    "print(f'Number of tiles: {n_tiles}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cb27b5-abe6-451d-86a8-d138d234fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_nrows=128, tile_ncols=128, tile_nchannels=8\n"
     ]
    }
   ],
   "source": [
    "# Get dataset shape\n",
    "tile_nrows,tile_ncols,tile_nchannels = dataset.element_spec[0].shape.as_list()\n",
    "print(f'{tile_nrows=}, {tile_ncols=}, {tile_nchannels=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f8f207-2194-4f52-90b8-925240673ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.tensorflow.org/tutorials/images/segmentation#optional_imbalanced_classes_and_class_weights\n",
    "def add_sample_weights(image, label):\n",
    "    # The weights for each class, with the constraint that:\n",
    "    #     sum(class_weights) == 1.0\n",
    "    class_weights = tf.constant([0.0, 1.0, 1.0, 1.0, 1.0, 1.0]) # Hard-coded for current dataset, zero weight for background\n",
    "    class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "    # Create an image of `sample_weights` by using the label at each pixel as an \n",
    "    # index into the `class weights` .\n",
    "    sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "    return image, label, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ed30c3-0a7c-4fbf-aabb-e8943f652387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset (tiles are originally ordered by image) and add sample weights\n",
    "dataset = dataset.shuffle(buffer_size=n_tiles)\n",
    "dataset = dataset.map(add_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67930d7e-9036-4cd3-ae99-a5fdc03f1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in training dataset: 81\n",
      "Number of batches in validation dataset: 35\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and validation\n",
    "# Note: Doing K-fold validation on Tensorflow datasets is not straightforward,\n",
    "# but can probably be done using generators. We'll do a simple split for now.\n",
    "n_val_tiles = int(VAL_FRAC*n_tiles)\n",
    "validation_dataset = dataset.take(n_val_tiles).batch(BATCH_SIZE)\n",
    "training_dataset = dataset.skip(n_val_tiles).batch(BATCH_SIZE)\n",
    "print(f'Number of batches in training dataset: {training_dataset.cardinality()}')\n",
    "print(f'Number of batches in validation dataset: {validation_dataset.cardinality()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45066075-7127-4231-a7b5-f9102a449f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save separate training and validation datasets (used later)\n",
    "tf.data.experimental.save(training_dataset,str(train_dataset_path))\n",
    "tf.data.experimental.save(validation_dataset,str(val_dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b5f4da-7bce-4a55-bf6d-73373ac5bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 8)]                                                              \n",
      "                                                                                                  \n",
      " augmentation (Sequential)      (None, None, None,   0           ['input_image[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " initial_convolution (Conv2D)   (None, None, None,   2336        ['augmentation[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " downsamp_res_1/2 (Sequential)  (None, None, None,   33024       ['initial_convolution[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " downsamp_res_1/4 (Sequential)  (None, None, None,   131584      ['downsamp_res_1/2[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " downsamp_res_1/8 (Sequential)  (None, None, None,   525312      ['downsamp_res_1/4[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " downsamp_res_1/16 (Sequential)  (None, None, None,   2099200    ['downsamp_res_1/8[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " downsamp_res_1/32 (Sequential)  (None, None, None,   8392704    ['downsamp_res_1/16[0][0]']      \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " upsamp_res_1/16 (Sequential)   (None, None, None,   8390656     ['downsamp_res_1/32[0][0]']      \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/16 (Conca  (None, None, None,   0          ['upsamp_res_1/16[0][0]',        \n",
      " tenate)                        1024)                             'downsamp_res_1/16[0][0]']      \n",
      "                                                                                                  \n",
      " upsamp_res_1/8 (Sequential)    (None, None, None,   8390656     ['skipconnection_res_1/16[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/8 (Concat  (None, None, None,   0          ['upsamp_res_1/8[0][0]',         \n",
      " enate)                         768)                              'downsamp_res_1/8[0][0]']       \n",
      "                                                                                                  \n",
      " upsamp_res_1/4 (Sequential)    (None, None, None,   3146752     ['skipconnection_res_1/8[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/4 (Concat  (None, None, None,   0          ['upsamp_res_1/4[0][0]',         \n",
      " enate)                         384)                              'downsamp_res_1/4[0][0]']       \n",
      "                                                                                                  \n",
      " upsamp_res_1/2 (Sequential)    (None, None, None,   786944      ['skipconnection_res_1/4[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/2 (Concat  (None, None, None,   0          ['upsamp_res_1/2[0][0]',         \n",
      " enate)                         192)                              'downsamp_res_1/2[0][0]']       \n",
      "                                                                                                  \n",
      " upsamp_res_1/1 (Sequential)    (None, None, None,   196864      ['skipconnection_res_1/2[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " skipconnection_res_1/1 (Concat  (None, None, None,   0          ['upsamp_res_1/1[0][0]',         \n",
      " enate)                         96)                               'initial_convolution[0][0]']    \n",
      "                                                                                                  \n",
      " classification (Conv2D)        (None, None, None,   5190        ['skipconnection_res_1/1[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,101,222\n",
      "Trainable params: 32,094,310\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the U-Net model\n",
    "unet = hyspec_cnn.unet(input_channels=tile_nchannels,\n",
    "                       output_channels=len(class_dict),\n",
    "                       first_layer_channels=32,\n",
    "                       depth = 5,\n",
    "               )\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8d4e3f-9134-4d3d-a650-3bafe600f64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "input_image\n",
      "----\n",
      "augmentation\n",
      "\trandom_flip\n",
      "----\n",
      "initial_convolution\n",
      "----\n",
      "downsamp_res_1/2\n",
      "\tconv2d\n",
      "\tbatch_normalization\n",
      "\tleaky_re_lu\n",
      "----\n",
      "downsamp_res_1/4\n",
      "\tconv2d_1\n",
      "\tbatch_normalization_1\n",
      "\tleaky_re_lu_1\n",
      "----\n",
      "downsamp_res_1/8\n",
      "\tconv2d_2\n",
      "\tbatch_normalization_2\n",
      "\tleaky_re_lu_2\n",
      "----\n",
      "downsamp_res_1/16\n",
      "\tconv2d_3\n",
      "\tbatch_normalization_3\n",
      "\tleaky_re_lu_3\n",
      "----\n",
      "downsamp_res_1/32\n",
      "\tconv2d_4\n",
      "\tbatch_normalization_4\n",
      "\tleaky_re_lu_4\n",
      "----\n",
      "upsamp_res_1/16\n",
      "\tconv2d_transpose\n",
      "\tbatch_normalization_5\n",
      "\tre_lu\n",
      "----\n",
      "skipconnection_res_1/16\n",
      "----\n",
      "upsamp_res_1/8\n",
      "\tconv2d_transpose_1\n",
      "\tbatch_normalization_6\n",
      "\tre_lu_1\n",
      "----\n",
      "skipconnection_res_1/8\n",
      "----\n",
      "upsamp_res_1/4\n",
      "\tconv2d_transpose_2\n",
      "\tbatch_normalization_7\n",
      "\tre_lu_2\n",
      "----\n",
      "skipconnection_res_1/4\n",
      "----\n",
      "upsamp_res_1/2\n",
      "\tconv2d_transpose_3\n",
      "\tbatch_normalization_8\n",
      "\tre_lu_3\n",
      "----\n",
      "skipconnection_res_1/2\n",
      "----\n",
      "upsamp_res_1/1\n",
      "\tconv2d_transpose_4\n",
      "\tbatch_normalization_9\n",
      "\tre_lu_4\n",
      "----\n",
      "skipconnection_res_1/1\n",
      "----\n",
      "classification\n"
     ]
    }
   ],
   "source": [
    "# Print layers with sublayers\n",
    "for layer in unet.layers:\n",
    "    print('----')\n",
    "    print(layer.name)\n",
    "    if hasattr(layer,'layers'):\n",
    "        for l in layer.layers:\n",
    "            print('\\t'+l.name)\n",
    "       # print(layer.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "993ae945-ae72-4251-b159-fc5469c3b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "model_save_filename = str(unet_model_save_dir) + '/unet_model.epoch{epoch:02d}-loss{val_loss:.6f}-acc{val_sparse_categorical_accuracy:.3f}.hdf5'\n",
    "callbacks =[tf.keras.callbacks.ModelCheckpoint(filepath = model_save_filename,\n",
    "                                               save_best_only=True,\n",
    "                                               verbose = 1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, verbose=1),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir= tensorboard_log_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d30375f-256a-4440-b853-f19f09bf7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer=tf.keras.optimizers.RMSprop(0.0001), \n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             weighted_metrics=['sparse_categorical_accuracy'], # Need weights to ignore background\n",
    "             metrics = []) # Sparse because classes are numbered, not one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "929da193-0023-48c4-839a-9483ee509c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1028 - sparse_categorical_accuracy: 0.5162\n",
      "Epoch 1: val_loss improved from inf to 0.05877, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch01-loss0.058766-acc0.726.hdf5\n",
      "81/81 [==============================] - 81s 986ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.5162 - val_loss: 0.0588 - val_sparse_categorical_accuracy: 0.7264 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0783 - sparse_categorical_accuracy: 0.6239\n",
      "Epoch 2: val_loss improved from 0.05877 to 0.05239, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch02-loss0.052389-acc0.782.hdf5\n",
      "81/81 [==============================] - 80s 984ms/step - loss: 0.0783 - sparse_categorical_accuracy: 0.6239 - val_loss: 0.0524 - val_sparse_categorical_accuracy: 0.7818 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0665 - sparse_categorical_accuracy: 0.6838\n",
      "Epoch 3: val_loss improved from 0.05239 to 0.04143, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch03-loss0.041432-acc0.819.hdf5\n",
      "81/81 [==============================] - 81s 993ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.6838 - val_loss: 0.0414 - val_sparse_categorical_accuracy: 0.8194 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0583 - sparse_categorical_accuracy: 0.7159\n",
      "Epoch 4: val_loss improved from 0.04143 to 0.03233, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch04-loss0.032329-acc0.874.hdf5\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.0323 - val_sparse_categorical_accuracy: 0.8737 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0574 - sparse_categorical_accuracy: 0.7464\n",
      "Epoch 5: val_loss improved from 0.03233 to 0.02384, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch05-loss0.023836-acc0.914.hdf5\n",
      "81/81 [==============================] - 80s 989ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9141 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0517 - sparse_categorical_accuracy: 0.7560\n",
      "Epoch 6: val_loss did not improve from 0.02384\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.8456 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0573 - sparse_categorical_accuracy: 0.7359\n",
      "Epoch 7: val_loss improved from 0.02384 to 0.01976, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch07-loss0.019763-acc0.928.hdf5\n",
      "81/81 [==============================] - 80s 992ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.0198 - val_sparse_categorical_accuracy: 0.9282 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0495 - sparse_categorical_accuracy: 0.7785\n",
      "Epoch 8: val_loss did not improve from 0.01976\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.0353 - val_sparse_categorical_accuracy: 0.8449 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0496 - sparse_categorical_accuracy: 0.7709\n",
      "Epoch 9: val_loss did not improve from 0.01976\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.7709 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.8832 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0480 - sparse_categorical_accuracy: 0.7858\n",
      "Epoch 10: val_loss improved from 0.01976 to 0.01710, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch10-loss0.017100-acc0.946.hdf5\n",
      "81/81 [==============================] - 80s 990ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.7858 - val_loss: 0.0171 - val_sparse_categorical_accuracy: 0.9457 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0493 - sparse_categorical_accuracy: 0.7771\n",
      "Epoch 11: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.7771 - val_loss: 0.0294 - val_sparse_categorical_accuracy: 0.8822 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0507 - sparse_categorical_accuracy: 0.7797\n",
      "Epoch 12: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0507 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9169 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0470 - sparse_categorical_accuracy: 0.8035\n",
      "Epoch 13: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.0201 - val_sparse_categorical_accuracy: 0.9319 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0427 - sparse_categorical_accuracy: 0.8130\n",
      "Epoch 14: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 955ms/step - loss: 0.0427 - sparse_categorical_accuracy: 0.8130 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9013 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0474 - sparse_categorical_accuracy: 0.7885\n",
      "Epoch 15: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.8987 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0400 - sparse_categorical_accuracy: 0.8273\n",
      "Epoch 16: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 956ms/step - loss: 0.0400 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.0195 - val_sparse_categorical_accuracy: 0.9273 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0421 - sparse_categorical_accuracy: 0.8124\n",
      "Epoch 17: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.8735 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0413 - sparse_categorical_accuracy: 0.8143\n",
      "Epoch 18: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.8674 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0362 - sparse_categorical_accuracy: 0.8405\n",
      "Epoch 19: val_loss did not improve from 0.01710\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 0.9197 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0388 - sparse_categorical_accuracy: 0.8299\n",
      "Epoch 20: val_loss improved from 0.01710 to 0.01476, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch20-loss0.014758-acc0.946.hdf5\n",
      "81/81 [==============================] - 80s 987ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0148 - val_sparse_categorical_accuracy: 0.9459 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0363 - sparse_categorical_accuracy: 0.8459\n",
      "Epoch 21: val_loss did not improve from 0.01476\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.8459 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9246 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0381 - sparse_categorical_accuracy: 0.8374\n",
      "Epoch 22: val_loss did not improve from 0.01476\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.8374 - val_loss: 0.0155 - val_sparse_categorical_accuracy: 0.9452 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0349 - sparse_categorical_accuracy: 0.8516\n",
      "Epoch 23: val_loss did not improve from 0.01476\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9413 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0370 - sparse_categorical_accuracy: 0.8395\n",
      "Epoch 24: val_loss did not improve from 0.01476\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.8395 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9448 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0325 - sparse_categorical_accuracy: 0.8611\n",
      "Epoch 25: val_loss did not improve from 0.01476\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.8611 - val_loss: 0.0179 - val_sparse_categorical_accuracy: 0.9269 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0306 - sparse_categorical_accuracy: 0.8654\n",
      "Epoch 26: val_loss did not improve from 0.01476\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0306 - sparse_categorical_accuracy: 0.8654 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9115 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0313 - sparse_categorical_accuracy: 0.8682\n",
      "Epoch 27: val_loss improved from 0.01476 to 0.01278, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch27-loss0.012784-acc0.948.hdf5\n",
      "81/81 [==============================] - 79s 979ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 0.9477 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0302 - sparse_categorical_accuracy: 0.8744\n",
      "Epoch 28: val_loss did not improve from 0.01278\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.8744 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9289 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0291 - sparse_categorical_accuracy: 0.8804\n",
      "Epoch 29: val_loss did not improve from 0.01278\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.8804 - val_loss: 0.0141 - val_sparse_categorical_accuracy: 0.9421 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0276 - sparse_categorical_accuracy: 0.8803\n",
      "Epoch 30: val_loss improved from 0.01278 to 0.01082, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch30-loss0.010816-acc0.959.hdf5\n",
      "81/81 [==============================] - 80s 981ms/step - loss: 0.0276 - sparse_categorical_accuracy: 0.8803 - val_loss: 0.0108 - val_sparse_categorical_accuracy: 0.9587 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0256 - sparse_categorical_accuracy: 0.8834\n",
      "Epoch 31: val_loss did not improve from 0.01082\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.8834 - val_loss: 0.0136 - val_sparse_categorical_accuracy: 0.9452 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0250 - sparse_categorical_accuracy: 0.8978\n",
      "Epoch 32: val_loss improved from 0.01082 to 0.01012, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch32-loss0.010116-acc0.959.hdf5\n",
      "81/81 [==============================] - 80s 981ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.0101 - val_sparse_categorical_accuracy: 0.9594 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0251 - sparse_categorical_accuracy: 0.8919\n",
      "Epoch 33: val_loss did not improve from 0.01012\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0251 - sparse_categorical_accuracy: 0.8919 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 0.9585 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0243 - sparse_categorical_accuracy: 0.8918\n",
      "Epoch 34: val_loss did not improve from 0.01012\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.8918 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 0.9569 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0242 - sparse_categorical_accuracy: 0.8894\n",
      "Epoch 35: val_loss improved from 0.01012 to 0.00995, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch35-loss0.009954-acc0.960.hdf5\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.0100 - val_sparse_categorical_accuracy: 0.9601 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0245 - sparse_categorical_accuracy: 0.8942\n",
      "Epoch 36: val_loss did not improve from 0.00995\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0245 - sparse_categorical_accuracy: 0.8942 - val_loss: 0.0154 - val_sparse_categorical_accuracy: 0.9272 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0194 - sparse_categorical_accuracy: 0.9137\n",
      "Epoch 37: val_loss improved from 0.00995 to 0.00684, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch37-loss0.006839-acc0.972.hdf5\n",
      "81/81 [==============================] - 80s 981ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9137 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 0.9715 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0233 - sparse_categorical_accuracy: 0.8979\n",
      "Epoch 38: val_loss did not improve from 0.00684\n",
      "81/81 [==============================] - 78s 955ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.0259 - val_sparse_categorical_accuracy: 0.8691 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0190 - sparse_categorical_accuracy: 0.9188\n",
      "Epoch 39: val_loss improved from 0.00684 to 0.00651, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch39-loss0.006505-acc0.975.hdf5\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9188 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 0.9748 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0201 - sparse_categorical_accuracy: 0.9183\n",
      "Epoch 40: val_loss did not improve from 0.00651\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0201 - sparse_categorical_accuracy: 0.9183 - val_loss: 0.0100 - val_sparse_categorical_accuracy: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0192 - sparse_categorical_accuracy: 0.9233\n",
      "Epoch 41: val_loss did not improve from 0.00651\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9715 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0144 - sparse_categorical_accuracy: 0.9390\n",
      "Epoch 42: val_loss improved from 0.00651 to 0.00580, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch42-loss0.005801-acc0.977.hdf5\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9390 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0180 - sparse_categorical_accuracy: 0.9196\n",
      "Epoch 43: val_loss improved from 0.00580 to 0.00424, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch43-loss0.004237-acc0.982.hdf5\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9196 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 0.9820 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0183 - sparse_categorical_accuracy: 0.9179\n",
      "Epoch 44: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 943ms/step - loss: 0.0183 - sparse_categorical_accuracy: 0.9179 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9671 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0170 - sparse_categorical_accuracy: 0.9233\n",
      "Epoch 45: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0166 - sparse_categorical_accuracy: 0.9292\n",
      "Epoch 46: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9292 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9632 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0135 - sparse_categorical_accuracy: 0.9397\n",
      "Epoch 47: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9549 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0129 - sparse_categorical_accuracy: 0.9427\n",
      "Epoch 48: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.0101 - val_sparse_categorical_accuracy: 0.9572 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0147 - sparse_categorical_accuracy: 0.9362\n",
      "Epoch 49: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 0.9809 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0140 - sparse_categorical_accuracy: 0.9428\n",
      "Epoch 50: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 78s 956ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9428 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0145 - sparse_categorical_accuracy: 0.9362\n",
      "Epoch 51: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9650 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0104 - sparse_categorical_accuracy: 0.9523\n",
      "Epoch 52: val_loss did not improve from 0.00424\n",
      "81/81 [==============================] - 77s 943ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0131 - sparse_categorical_accuracy: 0.9450\n",
      "Epoch 53: val_loss did not improve from 0.00424\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9617 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0086 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 54: val_loss improved from 0.00424 to 0.00264, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch54-loss0.002639-acc0.990.hdf5\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 0.9903 - lr: 2.0000e-05\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0083 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 55: val_loss improved from 0.00264 to 0.00244, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch55-loss0.002443-acc0.991.hdf5\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 0.9906 - lr: 2.0000e-05\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0080 - sparse_categorical_accuracy: 0.9679\n",
      "Epoch 56: val_loss improved from 0.00244 to 0.00190, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch56-loss0.001900-acc0.994.hdf5\n",
      "81/81 [==============================] - 78s 967ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 0.9939 - lr: 2.0000e-05\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0058 - sparse_categorical_accuracy: 0.9794\n",
      "Epoch 57: val_loss did not improve from 0.00190\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 0.9925 - lr: 2.0000e-05\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0050 - sparse_categorical_accuracy: 0.9826\n",
      "Epoch 58: val_loss did not improve from 0.00190\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 0.9913 - lr: 2.0000e-05\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0051 - sparse_categorical_accuracy: 0.9800\n",
      "Epoch 59: val_loss improved from 0.00190 to 0.00141, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch59-loss0.001411-acc0.995.hdf5\n",
      "81/81 [==============================] - 79s 976ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0014 - val_sparse_categorical_accuracy: 0.9953 - lr: 2.0000e-05\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0047 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 60: val_loss improved from 0.00141 to 0.00133, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch60-loss0.001332-acc0.995.hdf5\n",
      "81/81 [==============================] - 79s 972ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0013 - val_sparse_categorical_accuracy: 0.9955 - lr: 2.0000e-05\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0046 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 61: val_loss did not improve from 0.00133\n",
      "81/81 [==============================] - 78s 956ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 0.9872 - lr: 2.0000e-05\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0046 - sparse_categorical_accuracy: 0.9825\n",
      "Epoch 62: val_loss did not improve from 0.00133\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.0017 - val_sparse_categorical_accuracy: 0.9937 - lr: 2.0000e-05\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0049 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 63: val_loss did not improve from 0.00133\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.0016 - val_sparse_categorical_accuracy: 0.9934 - lr: 2.0000e-05\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0039 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 64: val_loss did not improve from 0.00133\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.0015 - val_sparse_categorical_accuracy: 0.9939 - lr: 2.0000e-05\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0043 - sparse_categorical_accuracy: 0.9829\n",
      "Epoch 65: val_loss did not improve from 0.00133\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0017 - val_sparse_categorical_accuracy: 0.9931 - lr: 2.0000e-05\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0042 - sparse_categorical_accuracy: 0.9835\n",
      "Epoch 66: val_loss improved from 0.00133 to 0.00073, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch66-loss0.000734-acc0.998.hdf5\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9835 - val_loss: 7.3423e-04 - val_sparse_categorical_accuracy: 0.9979 - lr: 2.0000e-05\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0035 - sparse_categorical_accuracy: 0.9869\n",
      "Epoch 67: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 0.9869 - lr: 2.0000e-05\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0041 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 68: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.0015 - val_sparse_categorical_accuracy: 0.9948 - lr: 2.0000e-05\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0045 - sparse_categorical_accuracy: 0.9822\n",
      "Epoch 69: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0015 - val_sparse_categorical_accuracy: 0.9944 - lr: 2.0000e-05\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0041 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 70: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0012 - val_sparse_categorical_accuracy: 0.9950 - lr: 2.0000e-05\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0032 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 71: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9883 - val_loss: 9.0624e-04 - val_sparse_categorical_accuracy: 0.9974 - lr: 2.0000e-05\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0025 - sparse_categorical_accuracy: 0.9924\n",
      "Epoch 72: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0011 - val_sparse_categorical_accuracy: 0.9963 - lr: 2.0000e-05\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0052 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 73: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.0010 - val_sparse_categorical_accuracy: 0.9966 - lr: 2.0000e-05\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0036 - sparse_categorical_accuracy: 0.9862\n",
      "Epoch 74: val_loss did not improve from 0.00073\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9862 - val_loss: 7.5154e-04 - val_sparse_categorical_accuracy: 0.9975 - lr: 2.0000e-05\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0031 - sparse_categorical_accuracy: 0.9882\n",
      "Epoch 75: val_loss improved from 0.00073 to 0.00053, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch75-loss0.000534-acc0.998.hdf5\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9882 - val_loss: 5.3351e-04 - val_sparse_categorical_accuracy: 0.9985 - lr: 2.0000e-05\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0039 - sparse_categorical_accuracy: 0.9860\n",
      "Epoch 76: val_loss improved from 0.00053 to 0.00052, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch76-loss0.000521-acc0.999.hdf5\n",
      "81/81 [==============================] - 79s 969ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9860 - val_loss: 5.2101e-04 - val_sparse_categorical_accuracy: 0.9987 - lr: 2.0000e-05\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0029 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 77: val_loss did not improve from 0.00052\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9890 - val_loss: 5.9650e-04 - val_sparse_categorical_accuracy: 0.9985 - lr: 2.0000e-05\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0031 - sparse_categorical_accuracy: 0.9878\n",
      "Epoch 78: val_loss did not improve from 0.00052\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9878 - val_loss: 5.7354e-04 - val_sparse_categorical_accuracy: 0.9983 - lr: 2.0000e-05\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0039 - sparse_categorical_accuracy: 0.9829\n",
      "Epoch 79: val_loss did not improve from 0.00052\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9829 - val_loss: 6.1685e-04 - val_sparse_categorical_accuracy: 0.9986 - lr: 2.0000e-05\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0038 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 80: val_loss did not improve from 0.00052\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9855 - val_loss: 6.3180e-04 - val_sparse_categorical_accuracy: 0.9981 - lr: 2.0000e-05\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0026 - sparse_categorical_accuracy: 0.9904\n",
      "Epoch 81: val_loss did not improve from 0.00052\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9904 - val_loss: 6.4478e-04 - val_sparse_categorical_accuracy: 0.9975 - lr: 2.0000e-05\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0024 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 82: val_loss improved from 0.00052 to 0.00050, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch82-loss0.000496-acc0.999.hdf5\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9910 - val_loss: 4.9639e-04 - val_sparse_categorical_accuracy: 0.9986 - lr: 2.0000e-05\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0027 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 83: val_loss did not improve from 0.00050\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9905 - val_loss: 6.5994e-04 - val_sparse_categorical_accuracy: 0.9977 - lr: 2.0000e-05\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0022 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 84: val_loss improved from 0.00050 to 0.00034, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch84-loss0.000341-acc0.999.hdf5\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9921 - val_loss: 3.4113e-04 - val_sparse_categorical_accuracy: 0.9989 - lr: 2.0000e-05\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0024 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 85: val_loss did not improve from 0.00034\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9923 - val_loss: 5.9024e-04 - val_sparse_categorical_accuracy: 0.9985 - lr: 2.0000e-05\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0026 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 86: val_loss did not improve from 0.00034\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9900 - val_loss: 4.0627e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 2.0000e-05\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9945\n",
      "Epoch 87: val_loss improved from 0.00034 to 0.00030, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch87-loss0.000295-acc0.999.hdf5\n",
      "81/81 [==============================] - 80s 988ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9945 - val_loss: 2.9528e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 2.0000e-05\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0033 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 88: val_loss did not improve from 0.00030\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9866 - val_loss: 4.2026e-04 - val_sparse_categorical_accuracy: 0.9989 - lr: 2.0000e-05\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0027 - sparse_categorical_accuracy: 0.9906\n",
      "Epoch 89: val_loss did not improve from 0.00030\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9906 - val_loss: 3.3736e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 2.0000e-05\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0022 - sparse_categorical_accuracy: 0.9913\n",
      "Epoch 90: val_loss did not improve from 0.00030\n",
      "81/81 [==============================] - 78s 955ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9913 - val_loss: 3.3634e-04 - val_sparse_categorical_accuracy: 0.9990 - lr: 2.0000e-05\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0026 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 91: val_loss did not improve from 0.00030\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9916 - val_loss: 9.3607e-04 - val_sparse_categorical_accuracy: 0.9962 - lr: 2.0000e-05\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0019 - sparse_categorical_accuracy: 0.9939\n",
      "Epoch 92: val_loss did not improve from 0.00030\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9939 - val_loss: 5.5329e-04 - val_sparse_categorical_accuracy: 0.9982 - lr: 2.0000e-05\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9934\n",
      "Epoch 93: val_loss improved from 0.00030 to 0.00025, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch93-loss0.000249-acc0.999.hdf5\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9934 - val_loss: 2.4932e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 2.0000e-05\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9931\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9931 - val_loss: 4.5652e-04 - val_sparse_categorical_accuracy: 0.9982 - lr: 2.0000e-05\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 95: val_loss improved from 0.00025 to 0.00015, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch95-loss0.000151-acc1.000.hdf5\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9925 - val_loss: 1.5084e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 4.0000e-06\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0022 - sparse_categorical_accuracy: 0.9922\n",
      "Epoch 96: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9922 - val_loss: 1.9023e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 4.0000e-06\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9956\n",
      "Epoch 97: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9956 - val_loss: 2.3182e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 4.0000e-06\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0026 - sparse_categorical_accuracy: 0.9887\n",
      "Epoch 98: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9887 - val_loss: 2.9532e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 4.0000e-06\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9954\n",
      "Epoch 99: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9954 - val_loss: 2.3858e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 4.0000e-06\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9952\n",
      "Epoch 100: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9952 - val_loss: 3.5472e-04 - val_sparse_categorical_accuracy: 0.9984 - lr: 4.0000e-06\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9933\n",
      "Epoch 101: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9933 - val_loss: 3.5437e-04 - val_sparse_categorical_accuracy: 0.9988 - lr: 4.0000e-06\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9943\n",
      "Epoch 102: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9943 - val_loss: 2.1430e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 4.0000e-06\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0024 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 103: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9923 - val_loss: 2.0664e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 4.0000e-06\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9953\n",
      "Epoch 104: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.5323e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 4.0000e-06\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 105: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9949 - val_loss: 1.8193e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 4.0000e-06\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0022 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 106: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9932 - val_loss: 2.5876e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 8.0000e-07\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 107: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9949 - val_loss: 2.4725e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 8.0000e-07\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9952\n",
      "Epoch 108: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9952 - val_loss: 3.0470e-04 - val_sparse_categorical_accuracy: 0.9989 - lr: 8.0000e-07\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9961\n",
      "Epoch 109: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9961 - val_loss: 2.9689e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 8.0000e-07\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 110: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9932 - val_loss: 1.9486e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 8.0000e-07\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0019 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 111: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9921 - val_loss: 2.4752e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 8.0000e-07\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0021 - sparse_categorical_accuracy: 0.9911\n",
      "Epoch 112: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9911 - val_loss: 2.7861e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 8.0000e-07\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9958\n",
      "Epoch 113: val_loss did not improve from 0.00015\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9958 - val_loss: 1.8176e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 8.0000e-07\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 114: val_loss improved from 0.00015 to 0.00014, saving model to /media/mha114/Massimal/Larvik_Olberg/Hyperspectral/20210825/OlbergAreaS/X_SavedKerasModels/unet_model.epoch114-loss0.000139-acc1.000.hdf5\n",
      "81/81 [==============================] - 79s 969ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9932 - val_loss: 1.3908e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 8.0000e-07\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9937\n",
      "Epoch 115: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9937 - val_loss: 1.8881e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 8.0000e-07\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 116: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9965 - val_loss: 1.8311e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 1.6000e-07\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0019 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 117: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9918 - val_loss: 2.2025e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 1.6000e-07\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9964\n",
      "Epoch 118: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9964 - val_loss: 1.9691e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 1.6000e-07\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9946\n",
      "Epoch 119: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9946 - val_loss: 1.7754e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 1.6000e-07\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9943\n",
      "Epoch 120: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9943 - val_loss: 2.5273e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.6000e-07\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9956\n",
      "Epoch 121: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9956 - val_loss: 3.0489e-04 - val_sparse_categorical_accuracy: 0.9990 - lr: 1.6000e-07\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9933\n",
      "Epoch 122: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 943ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9933 - val_loss: 2.3581e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 1.6000e-07\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9967\n",
      "Epoch 123: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 965ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9967 - val_loss: 2.4584e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.6000e-07\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9954\n",
      "Epoch 124: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9954 - val_loss: 1.8718e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 1.6000e-07\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9944\n",
      "Epoch 125: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9944 - val_loss: 2.4783e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.6000e-07\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 126: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9949 - val_loss: 2.1307e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 3.2000e-08\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 127: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9940 - val_loss: 1.5015e-04 - val_sparse_categorical_accuracy: 0.9998 - lr: 3.2000e-08\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 128: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9950 - val_loss: 1.9705e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 3.2000e-08\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9961\n",
      "Epoch 129: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9961 - val_loss: 2.9433e-04 - val_sparse_categorical_accuracy: 0.9990 - lr: 3.2000e-08\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9963\n",
      "Epoch 130: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9963 - val_loss: 3.1922e-04 - val_sparse_categorical_accuracy: 0.9989 - lr: 3.2000e-08\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 131: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9949 - val_loss: 2.8589e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 3.2000e-08\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0028 - sparse_categorical_accuracy: 0.9895\n",
      "Epoch 132: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9895 - val_loss: 2.2482e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 3.2000e-08\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9955\n",
      "Epoch 133: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9955 - val_loss: 1.9604e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 3.2000e-08\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9964\n",
      "Epoch 134: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9964 - val_loss: 1.7219e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 3.2000e-08\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9958\n",
      "Epoch 135: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9958 - val_loss: 2.0637e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 3.2000e-08\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9948\n",
      "Epoch 136: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 943ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9948 - val_loss: 2.3159e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 6.4000e-09\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 137: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9940 - val_loss: 2.7414e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 6.4000e-09\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9946\n",
      "Epoch 138: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9946 - val_loss: 2.6001e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 6.4000e-09\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9959\n",
      "Epoch 139: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9959 - val_loss: 1.8903e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 6.4000e-09\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0024 - sparse_categorical_accuracy: 0.9909\n",
      "Epoch 140: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9909 - val_loss: 2.6015e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 6.4000e-09\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9959\n",
      "Epoch 141: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9959 - val_loss: 1.7663e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 6.4000e-09\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9961\n",
      "Epoch 142: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9961 - val_loss: 2.5285e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 6.4000e-09\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 143: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9940 - val_loss: 2.2856e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 6.4000e-09\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9938\n",
      "Epoch 144: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9938 - val_loss: 2.1767e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 6.4000e-09\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 145: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9965 - val_loss: 2.6886e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 6.4000e-09\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0023 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 146: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9914 - val_loss: 1.7013e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 1.2800e-09\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9937\n",
      "Epoch 147: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9937 - val_loss: 1.9100e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 1.2800e-09\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9943\n",
      "Epoch 148: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9943 - val_loss: 1.7112e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 1.2800e-09\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9962\n",
      "Epoch 149: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9962 - val_loss: 1.6797e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 1.2800e-09\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9941\n",
      "Epoch 150: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9941 - val_loss: 2.5581e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.2800e-09\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9961\n",
      "Epoch 151: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9961 - val_loss: 2.4069e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.2800e-09\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9939\n",
      "Epoch 152: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9939 - val_loss: 1.8866e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 1.2800e-09\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 153: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 955ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9965 - val_loss: 1.6728e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 1.2800e-09\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 154: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9960 - val_loss: 2.8271e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 1.2800e-09\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9943\n",
      "Epoch 155: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
      "81/81 [==============================] - 77s 943ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9943 - val_loss: 2.5279e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.2800e-09\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9946\n",
      "Epoch 156: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9946 - val_loss: 2.2071e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 2.5600e-10\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 157: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9949 - val_loss: 2.4946e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 2.5600e-10\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9953\n",
      "Epoch 158: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.9606e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 2.5600e-10\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9958\n",
      "Epoch 159: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9958 - val_loss: 1.7622e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 2.5600e-10\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9944\n",
      "Epoch 160: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9944 - val_loss: 2.4984e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 2.5600e-10\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 9.8450e-04 - sparse_categorical_accuracy: 0.9976\n",
      "Epoch 161: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 9.8450e-04 - sparse_categorical_accuracy: 0.9976 - val_loss: 1.9254e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 2.5600e-10\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9955\n",
      "Epoch 162: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9955 - val_loss: 1.8402e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 2.5600e-10\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 163: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9940 - val_loss: 2.2052e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 2.5600e-10\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0018 - sparse_categorical_accuracy: 0.9935\n",
      "Epoch 164: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9935 - val_loss: 1.8023e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 2.5600e-10\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9938\n",
      "Epoch 165: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9938 - val_loss: 2.0430e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 2.5600e-10\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9972\n",
      "Epoch 166: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9972 - val_loss: 2.1684e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 5.1200e-11\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9957\n",
      "Epoch 167: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9957 - val_loss: 2.7731e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 5.1200e-11\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 168: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9923 - val_loss: 2.3163e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 5.1200e-11\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 169: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9960 - val_loss: 1.8958e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 5.1200e-11\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9962\n",
      "Epoch 170: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9962 - val_loss: 2.5604e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 5.1200e-11\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9955\n",
      "Epoch 171: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9955 - val_loss: 2.0680e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 5.1200e-11\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9957\n",
      "Epoch 172: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9957 - val_loss: 2.1649e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 5.1200e-11\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9961    \n",
      "Epoch 173: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9961 - val_loss: 1.5060e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 5.1200e-11\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9969\n",
      "Epoch 174: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9969 - val_loss: 1.4145e-04 - val_sparse_categorical_accuracy: 0.9998 - lr: 5.1200e-11\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 175: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9965 - val_loss: 2.3446e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 5.1200e-11\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 8.1268e-04 - sparse_categorical_accuracy: 0.9978\n",
      "Epoch 176: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 8.1268e-04 - sparse_categorical_accuracy: 0.9978 - val_loss: 1.8469e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 1.0240e-11\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9951\n",
      "Epoch 177: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 955ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9951 - val_loss: 3.1602e-04 - val_sparse_categorical_accuracy: 0.9989 - lr: 1.0240e-11\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9946\n",
      "Epoch 178: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9946 - val_loss: 1.9574e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 1.0240e-11\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 9.8953e-04 - sparse_categorical_accuracy: 0.9974\n",
      "Epoch 179: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 9.8953e-04 - sparse_categorical_accuracy: 0.9974 - val_loss: 2.8482e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 1.0240e-11\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 180: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9965 - val_loss: 1.8224e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 1.0240e-11\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 181: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9960 - val_loss: 2.5428e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 1.0240e-11\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0022 - sparse_categorical_accuracy: 0.9917\n",
      "Epoch 182: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9917 - val_loss: 2.5543e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 1.0240e-11\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9941\n",
      "Epoch 183: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9941 - val_loss: 2.9732e-04 - val_sparse_categorical_accuracy: 0.9990 - lr: 1.0240e-11\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9948\n",
      "Epoch 184: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9948 - val_loss: 1.9455e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 1.0240e-11\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0022 - sparse_categorical_accuracy: 0.9909\n",
      "Epoch 185: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 2.0479997905886727e-12.\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9909 - val_loss: 1.9158e-04 - val_sparse_categorical_accuracy: 0.9996 - lr: 1.0240e-11\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9972\n",
      "Epoch 186: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9972 - val_loss: 2.9366e-04 - val_sparse_categorical_accuracy: 0.9990 - lr: 2.0480e-12\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9959\n",
      "Epoch 187: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9959 - val_loss: 2.6241e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 2.0480e-12\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 188: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 78s 955ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9930 - val_loss: 2.4411e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 2.0480e-12\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 189: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9925 - val_loss: 1.9081e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 2.0480e-12\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 0.9961\n",
      "Epoch 190: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9961 - val_loss: 2.3675e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 2.0480e-12\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9963\n",
      "Epoch 191: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 943ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9963 - val_loss: 2.1330e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 2.0480e-12\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9936\n",
      "Epoch 192: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9936 - val_loss: 2.9111e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 2.0480e-12\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9959\n",
      "Epoch 193: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9959 - val_loss: 2.8307e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 2.0480e-12\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9937\n",
      "Epoch 194: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9937 - val_loss: 1.8901e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 2.0480e-12\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9949\n",
      "Epoch 195: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 4.0959995811773456e-13.\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9949 - val_loss: 1.5637e-04 - val_sparse_categorical_accuracy: 0.9997 - lr: 2.0480e-12\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 0.9952\n",
      "Epoch 196: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 944ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9952 - val_loss: 2.7599e-04 - val_sparse_categorical_accuracy: 0.9992 - lr: 4.0960e-13\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 0.9953\n",
      "Epoch 197: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.2468e-04 - val_sparse_categorical_accuracy: 0.9994 - lr: 4.0960e-13\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 0.9956\n",
      "Epoch 198: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9956 - val_loss: 2.7813e-04 - val_sparse_categorical_accuracy: 0.9991 - lr: 4.0960e-13\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 0.9967\n",
      "Epoch 199: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9967 - val_loss: 2.0513e-04 - val_sparse_categorical_accuracy: 0.9995 - lr: 4.0960e-13\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 0.9939\n",
      "Epoch 200: val_loss did not improve from 0.00014\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9939 - val_loss: 2.3711e-04 - val_sparse_categorical_accuracy: 0.9993 - lr: 4.0960e-13\n"
     ]
    }
   ],
   "source": [
    "# Fit model to dataset\n",
    "history = unet.fit(training_dataset,\n",
    "                   epochs=200,\n",
    "                   validation_data=validation_dataset,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0943595-16b6-4ef9-94e4-e0a64e161fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, history.params['epochs'] + 1)\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1549cf7e-2586-4d55-a2ae-872b3453ac5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, history.params['epochs'] + 1)\n",
    "train_acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
