{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000fc3cd-2530-40ea-9b47-5f69d649a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mha114/Dropbox/Python/massimal/dataset_specific/20220630_Juvika\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb8be3a-c0b3-4fd0-b407-5630d2d3de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/massimal/python/tools\")\n",
    "#sys.path.append(\"/tf/workspace/massimal/python/massimal/tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291d9a0e-d73d-425c-bf94-d138a70259c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage\n",
    "# \"Local import\" from massimal repository (https://github.com/mh-skjelvareid/massimal)\n",
    "import annotation, image_render, hyspec_io, misc, hyspec_stats, hyspec_cnn\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34579313-6073-46fb-87d9-46b669dd45b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 11:27:39.612140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 11:27:39.676908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 11:27:39.677243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d08739e-090d-4242-a908-1ee7be910a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU (see https://www.tensorflow.org/api_docs/python/tf/config/get_visible_devices )\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8332ab20-5a3c-4635-bc12-98852bf85c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50ddeb8-3624-4502-9998-872824dc2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TILE_SHAPE = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0102de1a-09d3-4719-8b78-1bf71cec586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "base_dir = '/media/mha114/Massimal/Bodo_Juvika/Hyperspectral/20220624/'\n",
    "#base_dir = '/massimal/data/Bodo_Juvika/Hyperspectral/20220624/'\n",
    "\n",
    "json_gray = base_dir + 'Area/M_Annotation/20220624_Juvika_AreaDetailed_v1/Annotations - grayscale/label_classes.json'\n",
    "annotation_dir = base_dir + 'Area/M_Annotation/20220624_Juvika_AreaDetailed_v1/Annotations - grayscale'\n",
    "hyspec_dir = base_dir + 'Area/2_R_rs'\n",
    "dataset_filename = base_dir + 'Area/M_TensorFlow_Datasets/128-TilesWithWeights/128-TilesWithWeights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f29d6ab-0613-48d9-bcd9-35223e09ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juvika_June2022_Pika_L_12-RGB.png\n",
      "Juvika_June2022_Pika_L_13-RGB.png\n",
      "Juvika_June2022_Pika_L_16-RGB.png\n"
     ]
    }
   ],
   "source": [
    "# Find paths to annotated images\n",
    "ann_file_paths_str = misc.file_pattern_search(annotation_dir,'*.png')\n",
    "ann_file_paths = [pathlib.Path(fn) for fn in ann_file_paths_str]\n",
    "for p in ann_file_paths:\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17cca0c5-1846-48bf-a341-a0ae8133e8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sand: 1\n",
      "Seagrass: 2\n",
      "Rockweed: 3\n",
      "Blue mussels: 4\n",
      "Deep water: 5\n",
      "Turf algae: 6\n"
     ]
    }
   ],
   "source": [
    "# Read annotation metadata file, show classes\n",
    "class_dict = annotation.read_hasty_metadata(json_gray)\n",
    "for class_name,class_ind in class_dict.items():\n",
    "    print(f'{class_name}: {class_ind}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af833717-dc34-4f23-b53e-a8b5a86e048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /media/mha114/Massimal/Bodo_Juvika/Hyperspectral/20220624/Area/M_Annotation/20220624_Juvika_AreaDetailed_v1/Annotations - grayscale/Juvika_June2022_Pika_L_12-RGB.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 11:32:02.036643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 11:32:02.037945: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1836000000 exceeds 10% of free system memory.\n",
      "2023-02-10 11:32:02.869675: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1754726400 exceeds 10% of free system memory.\n",
      "2023-02-10 11:32:03.694311: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1437204480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /media/mha114/Massimal/Bodo_Juvika/Hyperspectral/20220624/Area/M_Annotation/20220624_Juvika_AreaDetailed_v1/Annotations - grayscale/Juvika_June2022_Pika_L_13-RGB.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 11:32:20.251663: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1836000000 exceeds 10% of free system memory.\n",
      "2023-02-10 11:32:21.075186: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1754726400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /media/mha114/Massimal/Bodo_Juvika/Hyperspectral/20220624/Area/M_Annotation/20220624_Juvika_AreaDetailed_v1/Annotations - grayscale/Juvika_June2022_Pika_L_16-RGB.png\n",
      "hyspec_tiles.shape=TensorShape([257, 128, 128, 255]),\n",
      "annotation_tiles.shape=TensorShape([257, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Loop through images, spilt into tiles\n",
    "hyspec_tiles = []\n",
    "annotation_tiles = []\n",
    "for annotation_file in ann_file_paths:\n",
    "    print(f'Processing {annotation_file}')\n",
    "    # Load hyperspectral image\n",
    "    hyspec_file = pathlib.Path(hyspec_dir) / (annotation_file.stem[:-3] + 'Crop Wavelengths.bip.hdr')\n",
    "    hyspec_image, wl, rgb_ind, metadata = hyspec_io.load_envi_image(hyspec_file)\n",
    "    # Load annotation image\n",
    "    class_mask = skimage.io.imread(annotation_file)\n",
    "    class_mask[np.all(hyspec_image==0,axis=2)] = 0        # Don't include zero data\n",
    "        \n",
    "    # Extract tiles\n",
    "    X_tiles, y_tiles = hyspec_cnn.labeled_image_to_tensor_tiles(hyspec_image,class_mask,TILE_SHAPE,padding='VALID')\n",
    "    hyspec_tiles.append(X_tiles)\n",
    "    annotation_tiles.append(y_tiles)\n",
    "\n",
    "# Concatenate into single tensors\n",
    "hyspec_tiles = tf.concat(hyspec_tiles,axis=0)\n",
    "annotation_tiles = tf.concat(annotation_tiles,axis=0)\n",
    "\n",
    "# Show tensor sizes\n",
    "print(f'{hyspec_tiles.shape=},\\n{annotation_tiles.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f61b04-43b8-4b17-bc23-0bd71d74acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyspec_samples.shape=(209880, 255)\n"
     ]
    }
   ],
   "source": [
    "# Collect random spectra from data for building a PCA model\n",
    "# (Note: Can proably be optimized, this is just a \"quick and dirty\" way)\n",
    "hyspec_samples = []\n",
    "for tile in hyspec_tiles:\n",
    "    hyspec_samples.append(hyspec_stats.random_sample_image(np.array(tile)))\n",
    "hyspec_samples = np.concatenate(hyspec_samples,axis=0)\n",
    "print(f'{hyspec_samples.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6801466-1db5-4cfc-be16-0b3e498b8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Scaling and PCA model\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "X_sc = scaler.fit_transform(hyspec_samples)\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=10)   \n",
    "X_pca = pca.fit_transform(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd8cff8-c373-499e-94cc-e6ca499daf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance per component (%): [60.92722847 33.92305332  1.7357254   0.76552425  0.33200127  0.19798871\n",
      "  0.11314546  0.09408659  0.07947655  0.06992978]\n",
      "Total explained variance: 98.24 %\n"
     ]
    }
   ],
   "source": [
    "# Show explained variance in PCA model\n",
    "print(f'Explained variance per component (%): {pca.explained_variance_ratio_*100}')\n",
    "print(f'Total explained variance: {sum(pca.explained_variance_ratio_)*100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce369f10-5e8d-48c0-8d81-d40a80885298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 128, 128, 10)\n"
     ]
    }
   ],
   "source": [
    "# PCA transformation of image tiles\n",
    "pca_tiles = pca.transform(np.reshape(np.array(hyspec_tiles),[-1,hyspec_tiles.shape[-1]]))\n",
    "pca_tiles = pca_tiles.reshape([*hyspec_tiles.shape[0:3],-1])\n",
    "print(pca_tiles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870b413f-c435-4562-b905-c41d1839f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.1, 1: 2.1529073236778435, 2: 2.4850903217059495, 3: 4.394247481056919, 4: 20.657598875790473, 5: 6.452876590258547, 6: 23.89495425664711}\n"
     ]
    }
   ],
   "source": [
    "# Create tensorflow dataset, calculate class weights\n",
    "n_labeled_pixels = np.count_nonzero(annotation_tiles!=0)\n",
    "gamma = 0.8\n",
    "class_weights = {0:0.1}\n",
    "for class_name, class_index in class_dict.items():\n",
    "    class_weights[class_index] = (n_labeled_pixels / np.count_nonzero(annotation_tiles==class_index))**gamma\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "727e86a9-d680-4e4e-8f8b-058b46d34a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_weights = np.array(annotation_tiles!=0,dtype=np.float32)  # All annotated pixels get weight 1, background 0\n",
    "sample_weights = np.zeros_like(annotation_tiles,dtype=np.float32)\n",
    "for class_ind in class_weights.keys():\n",
    "    sample_weights[annotation_tiles==class_ind] = class_weights[class_ind]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((pca_tiles,annotation_tiles,sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3caec4c4-62fe-43bd-baa3-34c6189cfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(dataset,dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "649422b0-bb47-4809-82f8-212ac3843d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tf.data.experimental.load(dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f834850-0fdd-44b5-b9c2-f6dc1d0d3e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1727e-5ec8-46c8-bbc5-40175e98f7be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
