{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee1bbf5-cf5f-4c51-b23c-201284661c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable TensorFlow debugging info and warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 2: Info and warnings not displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add massimal tools folder to path\n",
    "import sys\n",
    "sys.path.append(\"/massimal/python/tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86d6258-75d4-4eae-a919-16da06175e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "#import tqdm\n",
    "import pickle\n",
    "import hyspec_cnn\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69c67e6-0662-4bfd-a4af-db2f0c22acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "base_dir = pathlib.Path('/massimal/data/Vega_Sola/Hyperspectral/20220823/Area')\n",
    "train_tiles_path = base_dir / '3a_PCA_TrainValidationSplit/Training/PCA-Tiles/20220823_Vega_Sola_Train_Tiles'\n",
    "val_tiles_path = base_dir / '3a_PCA_TrainValidationSplit/Validation/PCA-Tiles/20220823_Vega_Sola_Val_Tiles'\n",
    "\n",
    "unet_model_save_dir = base_dir / 'M_UnetModels'\n",
    "unet_model_save_dir.mkdir(exist_ok=True)\n",
    "tensorboard_log_dir = base_dir / 'M_TensorBoardLogs'\n",
    "tensorboard_log_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is used\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "OUTPUT_CHANNELS = 8\n",
    "BATCH_SIZE = 8\n",
    "DEPTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets \n",
    "train_dataset = tf.data.Dataset.load(str(train_tiles_path))\n",
    "val_dataset = tf.data.Dataset.load(str(val_tiles_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training tiles: 3266\n",
      "Number of validation tiles: 711\n",
      "Tile data shape (PCA tiles): (128, 128, 8)\n"
     ]
    }
   ],
   "source": [
    "# Get number of tiles in each dataset, and dataset shape\n",
    "n_tiles_train = train_dataset.cardinality()\n",
    "n_tiles_val = val_dataset.cardinality()\n",
    "tile_nrows,tile_ncols,tile_nchannels = train_dataset.element_spec[0].shape.as_list()\n",
    "print(f'Number of training tiles: {n_tiles_train}')\n",
    "print(f'Number of validation tiles: {n_tiles_val}')\n",
    "print(f'Tile data shape (PCA tiles): {(tile_nrows,tile_ncols,tile_nchannels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.tensorflow.org/tutorials/images/segmentation#optional_imbalanced_classes_and_class_weights\n",
    "def add_sample_weights(image, label, name):\n",
    "    class_weights = tf.constant([0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) # Hard-coded for 7 classes\n",
    "    class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "    # Create an image of `sample_weights` by using the label at each pixel as an \n",
    "    # index into the `class weights` .\n",
    "    sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "    return image, label, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training dataset (tiles are originally ordered by image) and add sample weights\n",
    "train_dataset = train_dataset.shuffle(buffer_size=n_tiles_train)\n",
    "train_dataset = train_dataset.map(add_sample_weights)\n",
    "val_dataset = val_dataset.map(add_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch datasets\n",
    "train_dataset_batch = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset_batch = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 8)]                                                              \n",
      "                                                                                                  \n",
      " augmentation (Sequential)      (None, None, None,   0           ['input_image[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " initial_convolution (Conv2D)   (None, None, None,   2336        ['augmentation[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " downsamp_res_1/2 (Sequential)  (None, None, None,   33024       ['initial_convolution[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " downsamp_res_1/4 (Sequential)  (None, None, None,   131584      ['downsamp_res_1/2[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " downsamp_res_1/8 (Sequential)  (None, None, None,   525312      ['downsamp_res_1/4[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " downsamp_res_1/16 (Sequential)  (None, None, None,   2099200    ['downsamp_res_1/8[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " upsamp_res_1/8 (Sequential)    (None, None, None,   2098176     ['downsamp_res_1/16[0][0]']      \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/8 (Concat  (None, None, None,   0          ['upsamp_res_1/8[0][0]',         \n",
      " enate)                         512)                              'downsamp_res_1/8[0][0]']       \n",
      "                                                                                                  \n",
      " upsamp_res_1/4 (Sequential)    (None, None, None,   2098176     ['skipconnection_res_1/8[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/4 (Concat  (None, None, None,   0          ['upsamp_res_1/4[0][0]',         \n",
      " enate)                         384)                              'downsamp_res_1/4[0][0]']       \n",
      "                                                                                                  \n",
      " upsamp_res_1/2 (Sequential)    (None, None, None,   786944      ['skipconnection_res_1/4[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " skipconnection_res_1/2 (Concat  (None, None, None,   0          ['upsamp_res_1/2[0][0]',         \n",
      " enate)                         192)                              'downsamp_res_1/2[0][0]']       \n",
      "                                                                                                  \n",
      " upsamp_res_1/1 (Sequential)    (None, None, None,   196864      ['skipconnection_res_1/2[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " skipconnection_res_1/1 (Concat  (None, None, None,   0          ['upsamp_res_1/1[0][0]',         \n",
      " enate)                         96)                               'initial_convolution[0][0]']    \n",
      "                                                                                                  \n",
      " classification (Conv2D)        (None, None, None,   6920        ['skipconnection_res_1/1[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,978,536\n",
      "Trainable params: 7,975,208\n",
      "Non-trainable params: 3,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the U-Net model\n",
    "unet = hyspec_cnn.unet(input_channels=tile_nchannels,\n",
    "                       output_channels=OUTPUT_CHANNELS,\n",
    "                       first_layer_channels=32,\n",
    "                       depth = DEPTH,\n",
    "               )\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "input_image\n",
      "----\n",
      "augmentation\n",
      "\trandom_flip\n",
      "----\n",
      "initial_convolution\n",
      "----\n",
      "downsamp_res_1/2\n",
      "\tconv2d\n",
      "\tbatch_normalization\n",
      "\tleaky_re_lu\n",
      "----\n",
      "downsamp_res_1/4\n",
      "\tconv2d_1\n",
      "\tbatch_normalization_1\n",
      "\tleaky_re_lu_1\n",
      "----\n",
      "downsamp_res_1/8\n",
      "\tconv2d_2\n",
      "\tbatch_normalization_2\n",
      "\tleaky_re_lu_2\n",
      "----\n",
      "downsamp_res_1/16\n",
      "\tconv2d_3\n",
      "\tbatch_normalization_3\n",
      "\tleaky_re_lu_3\n",
      "----\n",
      "upsamp_res_1/8\n",
      "\tconv2d_transpose\n",
      "\tbatch_normalization_4\n",
      "\tre_lu\n",
      "----\n",
      "skipconnection_res_1/8\n",
      "----\n",
      "upsamp_res_1/4\n",
      "\tconv2d_transpose_1\n",
      "\tbatch_normalization_5\n",
      "\tre_lu_1\n",
      "----\n",
      "skipconnection_res_1/4\n",
      "----\n",
      "upsamp_res_1/2\n",
      "\tconv2d_transpose_2\n",
      "\tbatch_normalization_6\n",
      "\tre_lu_2\n",
      "----\n",
      "skipconnection_res_1/2\n",
      "----\n",
      "upsamp_res_1/1\n",
      "\tconv2d_transpose_3\n",
      "\tbatch_normalization_7\n",
      "\tre_lu_3\n",
      "----\n",
      "skipconnection_res_1/1\n",
      "----\n",
      "classification\n"
     ]
    }
   ],
   "source": [
    "# Print layers with sublayers\n",
    "for layer in unet.layers:\n",
    "    print('----')\n",
    "    print(layer.name)\n",
    "    if hasattr(layer,'layers'):\n",
    "        for l in layer.layers:\n",
    "            print('\\t'+l.name)\n",
    "       # print(layer.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "model_save_filename = str(unet_model_save_dir) + '/unet_model.depth' + str(DEPTH) +'.epoch{epoch:02d}-loss{val_loss:.6f}-acc{val_sparse_categorical_accuracy:.3f}.hdf5'\n",
    "callbacks =[tf.keras.callbacks.ModelCheckpoint(filepath = model_save_filename,\n",
    "                                               save_best_only=True,\n",
    "                                               verbose = 1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, verbose=1),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir= tensorboard_log_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch{epoch:02d}-loss{val_loss:.6f}-acc{val_sparse_categorical_accuracy:.3f}.hdf5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "unet.compile(optimizer=tf.keras.optimizers.RMSprop(0.0001), \n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             weighted_metrics=['sparse_categorical_accuracy'], # Need weights to ignore background\n",
    "             metrics = []) # Sparse because classes are numbered, not one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tensorboard_log_dir)\n",
    "#%tensorboard --logdir /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_TensorBoardLogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1154 - sparse_categorical_accuracy: 0.4706\n",
      "Epoch 1: val_loss improved from inf to 0.08209, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch01-loss0.082087-acc0.587.hdf5\n",
      "409/409 [==============================] - 112s 255ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.0821 - val_sparse_categorical_accuracy: 0.5866 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.5695\n",
      "Epoch 2: val_loss improved from 0.08209 to 0.07243, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch02-loss0.072435-acc0.661.hdf5\n",
      "409/409 [==============================] - 105s 253ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.5695 - val_loss: 0.0724 - val_sparse_categorical_accuracy: 0.6609 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0845 - sparse_categorical_accuracy: 0.6024\n",
      "Epoch 3: val_loss improved from 0.07243 to 0.06779, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch03-loss0.067786-acc0.652.hdf5\n",
      "409/409 [==============================] - 104s 252ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.6024 - val_loss: 0.0678 - val_sparse_categorical_accuracy: 0.6520 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0804 - sparse_categorical_accuracy: 0.6193\n",
      "Epoch 4: val_loss did not improve from 0.06779\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.6193 - val_loss: 0.0767 - val_sparse_categorical_accuracy: 0.6271 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0764 - sparse_categorical_accuracy: 0.6366\n",
      "Epoch 5: val_loss did not improve from 0.06779\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.6366 - val_loss: 0.0897 - val_sparse_categorical_accuracy: 0.6011 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0716 - sparse_categorical_accuracy: 0.6612\n",
      "Epoch 6: val_loss did not improve from 0.06779\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.6612 - val_loss: 0.0684 - val_sparse_categorical_accuracy: 0.6681 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0689 - sparse_categorical_accuracy: 0.6737\n",
      "Epoch 7: val_loss improved from 0.06779 to 0.05611, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch07-loss0.056109-acc0.719.hdf5\n",
      "409/409 [==============================] - 103s 249ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.6737 - val_loss: 0.0561 - val_sparse_categorical_accuracy: 0.7192 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0667 - sparse_categorical_accuracy: 0.6845\n",
      "Epoch 8: val_loss did not improve from 0.05611\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.6845 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.7275 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0639 - sparse_categorical_accuracy: 0.6989\n",
      "Epoch 9: val_loss did not improve from 0.05611\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.6989 - val_loss: 0.0677 - val_sparse_categorical_accuracy: 0.6068 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0621 - sparse_categorical_accuracy: 0.7122\n",
      "Epoch 10: val_loss did not improve from 0.05611\n",
      "409/409 [==============================] - 104s 252ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.7122 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.6950 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0582 - sparse_categorical_accuracy: 0.7272\n",
      "Epoch 11: val_loss did not improve from 0.05611\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.7272 - val_loss: 0.0651 - val_sparse_categorical_accuracy: 0.6989 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0575 - sparse_categorical_accuracy: 0.7331\n",
      "Epoch 12: val_loss did not improve from 0.05611\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.7331 - val_loss: 0.0595 - val_sparse_categorical_accuracy: 0.6779 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0545 - sparse_categorical_accuracy: 0.7460\n",
      "Epoch 13: val_loss improved from 0.05611 to 0.05546, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch13-loss0.055457-acc0.719.hdf5\n",
      "409/409 [==============================] - 103s 249ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.7460 - val_loss: 0.0555 - val_sparse_categorical_accuracy: 0.7194 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0529 - sparse_categorical_accuracy: 0.7526\n",
      "Epoch 14: val_loss did not improve from 0.05546\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.7526 - val_loss: 0.0575 - val_sparse_categorical_accuracy: 0.7283 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0520 - sparse_categorical_accuracy: 0.7561\n",
      "Epoch 15: val_loss did not improve from 0.05546\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.7561 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.7226 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0502 - sparse_categorical_accuracy: 0.7613\n",
      "Epoch 16: val_loss improved from 0.05546 to 0.05416, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch16-loss0.054159-acc0.710.hdf5\n",
      "409/409 [==============================] - 104s 251ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.0542 - val_sparse_categorical_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0486 - sparse_categorical_accuracy: 0.7754\n",
      "Epoch 17: val_loss did not improve from 0.05416\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.0657 - val_sparse_categorical_accuracy: 0.6320 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0472 - sparse_categorical_accuracy: 0.7795\n",
      "Epoch 18: val_loss did not improve from 0.05416\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.7795 - val_loss: 0.0563 - val_sparse_categorical_accuracy: 0.7245 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0455 - sparse_categorical_accuracy: 0.7887\n",
      "Epoch 19: val_loss did not improve from 0.05416\n",
      "409/409 [==============================] - 104s 251ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.0547 - val_sparse_categorical_accuracy: 0.7407 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0463 - sparse_categorical_accuracy: 0.7831\n",
      "Epoch 20: val_loss did not improve from 0.05416\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.7831 - val_loss: 0.0548 - val_sparse_categorical_accuracy: 0.7215 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0443 - sparse_categorical_accuracy: 0.7934\n",
      "Epoch 21: val_loss did not improve from 0.05416\n",
      "409/409 [==============================] - 103s 247ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.7934 - val_loss: 0.0705 - val_sparse_categorical_accuracy: 0.6614 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0433 - sparse_categorical_accuracy: 0.7973\n",
      "Epoch 22: val_loss did not improve from 0.05416\n",
      "409/409 [==============================] - 104s 246ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.0664 - val_sparse_categorical_accuracy: 0.6828 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0423 - sparse_categorical_accuracy: 0.8008\n",
      "Epoch 23: val_loss improved from 0.05416 to 0.04984, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch23-loss0.049841-acc0.764.hdf5\n",
      "409/409 [==============================] - 103s 249ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.7643 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0414 - sparse_categorical_accuracy: 0.8076\n",
      "Epoch 24: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.0781 - val_sparse_categorical_accuracy: 0.6978 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0403 - sparse_categorical_accuracy: 0.8105\n",
      "Epoch 25: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.0604 - val_sparse_categorical_accuracy: 0.7119 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0405 - sparse_categorical_accuracy: 0.8109\n",
      "Epoch 26: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0405 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.6990 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0391 - sparse_categorical_accuracy: 0.8170\n",
      "Epoch 27: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.0649 - val_sparse_categorical_accuracy: 0.7085 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0376 - sparse_categorical_accuracy: 0.8243\n",
      "Epoch 28: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.7763 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0363 - sparse_categorical_accuracy: 0.8303\n",
      "Epoch 29: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.8303 - val_loss: 0.0533 - val_sparse_categorical_accuracy: 0.7542 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0356 - sparse_categorical_accuracy: 0.8328\n",
      "Epoch 30: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.0645 - val_sparse_categorical_accuracy: 0.7156 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0358 - sparse_categorical_accuracy: 0.8323\n",
      "Epoch 31: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0358 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.0613 - val_sparse_categorical_accuracy: 0.7229 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0347 - sparse_categorical_accuracy: 0.8356\n",
      "Epoch 32: val_loss did not improve from 0.04984\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0347 - sparse_categorical_accuracy: 0.8356 - val_loss: 0.0549 - val_sparse_categorical_accuracy: 0.7255 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0341 - sparse_categorical_accuracy: 0.8382\n",
      "Epoch 33: val_loss did not improve from 0.04984\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.8382 - val_loss: 0.0615 - val_sparse_categorical_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0283 - sparse_categorical_accuracy: 0.8684\n",
      "Epoch 34: val_loss improved from 0.04984 to 0.04980, saving model to /massimal/data/Vega_Sola/Hyperspectral/20220823/Area/M_UnetModels/unet_model.depth4.epoch34-loss0.049797-acc0.764.hdf5\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.8684 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.7636 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0273 - sparse_categorical_accuracy: 0.8752\n",
      "Epoch 35: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.8752 - val_loss: 0.0518 - val_sparse_categorical_accuracy: 0.7585 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0267 - sparse_categorical_accuracy: 0.8759\n",
      "Epoch 36: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0267 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.7519 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0265 - sparse_categorical_accuracy: 0.8772\n",
      "Epoch 37: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 106s 247ms/step - loss: 0.0265 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.0568 - val_sparse_categorical_accuracy: 0.7376 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0256 - sparse_categorical_accuracy: 0.8828\n",
      "Epoch 38: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 112s 248ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.8828 - val_loss: 0.0600 - val_sparse_categorical_accuracy: 0.7266 - lr: 2.0000e-05\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0260 - sparse_categorical_accuracy: 0.8810\n",
      "Epoch 39: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 106s 247ms/step - loss: 0.0260 - sparse_categorical_accuracy: 0.8810 - val_loss: 0.0534 - val_sparse_categorical_accuracy: 0.7565 - lr: 2.0000e-05\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0250 - sparse_categorical_accuracy: 0.8845\n",
      "Epoch 40: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.8845 - val_loss: 0.0564 - val_sparse_categorical_accuracy: 0.7470 - lr: 2.0000e-05\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0242 - sparse_categorical_accuracy: 0.8887\n",
      "Epoch 41: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.7678 - lr: 2.0000e-05\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0244 - sparse_categorical_accuracy: 0.8879\n",
      "Epoch 42: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 246ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.7586 - lr: 2.0000e-05\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0240 - sparse_categorical_accuracy: 0.8895\n",
      "Epoch 43: val_loss did not improve from 0.04980\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0240 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.7747 - lr: 2.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0231 - sparse_categorical_accuracy: 0.8928\n",
      "Epoch 44: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.0550 - val_sparse_categorical_accuracy: 0.7542 - lr: 4.0000e-06\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0225 - sparse_categorical_accuracy: 0.8974\n",
      "Epoch 45: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.8974 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.7597 - lr: 4.0000e-06\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0220 - sparse_categorical_accuracy: 0.8999\n",
      "Epoch 46: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.0526 - val_sparse_categorical_accuracy: 0.7674 - lr: 4.0000e-06\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0228 - sparse_categorical_accuracy: 0.8972\n",
      "Epoch 47: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.7613 - lr: 4.0000e-06\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0222 - sparse_categorical_accuracy: 0.8976\n",
      "Epoch 48: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 105s 248ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.7556 - lr: 4.0000e-06\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0223 - sparse_categorical_accuracy: 0.8974\n",
      "Epoch 49: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 104s 247ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.8974 - val_loss: 0.0558 - val_sparse_categorical_accuracy: 0.7552 - lr: 4.0000e-06\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0217 - sparse_categorical_accuracy: 0.9018\n",
      "Epoch 50: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.0561 - val_sparse_categorical_accuracy: 0.7486 - lr: 4.0000e-06\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0221 - sparse_categorical_accuracy: 0.8990\n",
      "Epoch 51: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.0536 - val_sparse_categorical_accuracy: 0.7650 - lr: 4.0000e-06\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0222 - sparse_categorical_accuracy: 0.8983\n",
      "Epoch 52: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 109s 248ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.0555 - val_sparse_categorical_accuracy: 0.7562 - lr: 4.0000e-06\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0217 - sparse_categorical_accuracy: 0.9011\n",
      "Epoch 53: val_loss did not improve from 0.04980\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "409/409 [==============================] - 116s 252ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9011 - val_loss: 0.0562 - val_sparse_categorical_accuracy: 0.7520 - lr: 4.0000e-06\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0216 - sparse_categorical_accuracy: 0.9012\n",
      "Epoch 54: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 109s 248ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.7534 - lr: 8.0000e-07\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0216 - sparse_categorical_accuracy: 0.9006\n",
      "Epoch 55: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 103s 247ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9006 - val_loss: 0.0549 - val_sparse_categorical_accuracy: 0.7570 - lr: 8.0000e-07\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0215 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 56: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 104s 249ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.0547 - val_sparse_categorical_accuracy: 0.7606 - lr: 8.0000e-07\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0216 - sparse_categorical_accuracy: 0.9009\n",
      "Epoch 57: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 104s 247ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.0550 - val_sparse_categorical_accuracy: 0.7591 - lr: 8.0000e-07\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0214 - sparse_categorical_accuracy: 0.9028\n",
      "Epoch 58: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.0561 - val_sparse_categorical_accuracy: 0.7550 - lr: 8.0000e-07\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9051\n",
      "Epoch 59: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.7562 - lr: 8.0000e-07\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0213 - sparse_categorical_accuracy: 0.9035\n",
      "Epoch 60: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.0549 - val_sparse_categorical_accuracy: 0.7608 - lr: 8.0000e-07\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0216 - sparse_categorical_accuracy: 0.9014\n",
      "Epoch 61: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.0553 - val_sparse_categorical_accuracy: 0.7575 - lr: 8.0000e-07\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9039\n",
      "Epoch 62: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.7514 - lr: 8.0000e-07\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 63: val_loss did not improve from 0.04980\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.0570 - val_sparse_categorical_accuracy: 0.7514 - lr: 8.0000e-07\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0212 - sparse_categorical_accuracy: 0.9031\n",
      "Epoch 64: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.0558 - val_sparse_categorical_accuracy: 0.7553 - lr: 1.6000e-07\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0213 - sparse_categorical_accuracy: 0.9025\n",
      "Epoch 65: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 248ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9025 - val_loss: 0.0560 - val_sparse_categorical_accuracy: 0.7565 - lr: 1.6000e-07\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0212 - sparse_categorical_accuracy: 0.9020\n",
      "Epoch 66: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.7581 - lr: 1.6000e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0214 - sparse_categorical_accuracy: 0.9022\n",
      "Epoch 67: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9022 - val_loss: 0.0553 - val_sparse_categorical_accuracy: 0.7589 - lr: 1.6000e-07\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0216 - sparse_categorical_accuracy: 0.9003\n",
      "Epoch 68: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 103s 248ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9003 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.7573 - lr: 1.6000e-07\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9038\n",
      "Epoch 69: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.0560 - val_sparse_categorical_accuracy: 0.7547 - lr: 1.6000e-07\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9047\n",
      "Epoch 70: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.7569 - lr: 1.6000e-07\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0210 - sparse_categorical_accuracy: 0.9030\n",
      "Epoch 71: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.0554 - val_sparse_categorical_accuracy: 0.7586 - lr: 1.6000e-07\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0213 - sparse_categorical_accuracy: 0.9040\n",
      "Epoch 72: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9040 - val_loss: 0.0554 - val_sparse_categorical_accuracy: 0.7603 - lr: 1.6000e-07\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0214 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 73: val_loss did not improve from 0.04980\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.0548 - val_sparse_categorical_accuracy: 0.7621 - lr: 1.6000e-07\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0213 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 74: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.0550 - val_sparse_categorical_accuracy: 0.7610 - lr: 3.2000e-08\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9048\n",
      "Epoch 75: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9048 - val_loss: 0.0555 - val_sparse_categorical_accuracy: 0.7571 - lr: 3.2000e-08\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9049\n",
      "Epoch 76: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9049 - val_loss: 0.0558 - val_sparse_categorical_accuracy: 0.7576 - lr: 3.2000e-08\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 77: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 247ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.0547 - val_sparse_categorical_accuracy: 0.7622 - lr: 3.2000e-08\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9036\n",
      "Epoch 78: val_loss did not improve from 0.04980\n",
      "409/409 [==============================] - 102s 248ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.0555 - val_sparse_categorical_accuracy: 0.7574 - lr: 3.2000e-08\n",
      "Epoch 79/100\n",
      " 51/409 [==>...........................] - ETA: 1:24 - loss: 0.0227 - sparse_categorical_accuracy: 0.8994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit model to dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model to dataset\n",
    "history = unet.fit(train_dataset.batch(BATCH_SIZE),\n",
    "                   epochs=100,\n",
    "                   validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "                   callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
